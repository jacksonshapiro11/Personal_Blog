# Ep17. Welcome Jensen Huang | BG2 W/ Bill Gurley & Brad Gerstner

![](https://wsrv.nl/?url=https%3A%2F%2Fd3t3ozftmdmh3i.cloudfront.net%2Fstaging%2Fpodcast_uploaded_nologo%2F40236188%2F40236188-1706073929930-da002b9be1355.jpg&w=100&h=100)

### Metadata

- Author: BG2Pod with Brad Gerstner and Bill Gurley
- Full Title: Ep17. Welcome Jensen Huang | BG2 W/ Bill Gurley & Brad Gerstner
- Category: #podcasts



- URL: https://share.snipd.com/episode/a6318765-952e-4fdd-93ac-0b75e1b6a414

### Highlights

- Master the Layers: The Future of AI Lies in Understanding Its Taxonomy
  Summary:
  Artificial intelligence operates on multiple layers, each requiring distinct skills and presenting unique opportunities.
  While models and GPUs are fundamental to AI, they are not sufficient on their own; one needs to comprehend the broader stack of AI technologies. Rapid advancements, such as the recent construction of massive GPU clusters in record time, emphasize the increasing scale and capabilities of AI infrastructure.
  Future developments will likely focus on distributed training and federated learning, which allow for scalable computing beyond traditional models.
  The evolution towards multimodal AI and enhanced inference capabilities indicate a significant shift, where the timing and reasoning in response will impact the deployment of intelligence.
  Understanding the implications of these advancements is crucial for navigating the ecosystem and leveraging opportunities in the AI industry, where the segmentation of intelligence across various use cases will become increasingly prominent.
  Transcript:
  Speaker 1
  A model is an essential ingredient for artificial intelligence. It's necessary but not sufficient. Correct. And artificial intelligence is a capability, but for what? Right. Then what's the application? Right. The artificial intelligence for software-driving cars is related to the artificial intelligence for human or robots, but it's not the same. Which is related to the artificial intelligence for a chatbot, but not the same. Correct. And so you have to understand the taxonomy of- Stack. Yeah, of the stack. And at every layer of the stack, there will be opportunities, but not infinite opportunities for everybody at every single layer of the stack. Now, I just said something. All you have to do is replace the word model with GPU. In fact, this was the great observation of our company 32 years ago, that there's a fundamental difference between GPU, graphics chip or GPU, versus accelerated computing. And accelerated computing is a different thing than the work that we do with AI infrastructure. It's related, but it's not exactly the same. It's built on top of each other. It's not not exactly the same. And each one of these layers of abstraction requires fundamental different skills. Somebody who's really, really good at building GPUs have no clue how to be an accelerated computing company. There are a whole lot of people who build GPUs. And I don't know which one came to me. We invented the GPU, but you know that we're not the only company that makes GPUs today. Correct. You know, and so there are GPUs everywhere. But they're not accelerated computing companies. And there are a lot of people who, you know, they're accelerators, accelerators that does application acceleration. But that's different than an accelerated computing company. And so, for example, a very specialized AI application. Right. That could be a very successful thing. Correct. Met as MTIA. That's right. But it might not be the type of company that had broad reach and broad capabilities. And so you've got to decide where you want to be. There's opportunities probably in all these different areas. But like building companies, you have to be mindful of the shifting of the ecosystem and what gets commoditized over time, recognizing what's a feature versus a product versus a company. For sure. Okay. I just went through. Okay. And there's a lot of different ways you can think about this.
  Speaker 2
  Of course, there's one new entrant that has the money, the smarts, the ambition. That's x.ai, right? And well, there are reports out there that you and Larry and Elon had dinner. They talked to you out of 100,000 H100s. They went to Memphis and built a large coherent super cluster in a matter of months. So first, three points don't make a line.
  Speaker 1
  Yes, I had dinner with them. Causality is it.
  Speaker 2
  What do you think about their ability to stand up that super cluster? And there's talk out there that they want another 100,000 H200s to expand the size of that super cluster. First, talk to us a little bit about X and their ambitions and what they've achieved, but also, are we already at the age of clusters of 200,000 and 300,000 GPUs?
  Speaker 1
  The answer is yes. And then the first of all, acknowledgement of achievement where it's deserved. From the moment of concept to a data center that's ready for NVIDIA to have our gear there to the moment that we powered it on, had it all hooked up, and it did its first training. Yeah. Okay? Correct. So that first part, just building a massive factory, liquid-cooled, energized, permitted in the short time that was done, I mean, that is like superhuman. Right. Yeah, there's – and as far as I know, there's only one person in the world who could do that. I mean, Elon is singular in this understanding of engineering and construction and large systems and marshaling resources. Incredible. Yeah, just – And of course, then his engineering team is extraordinary. I mean, the software team is great. The networking team is great. The infrastructure team is great. Elon understands this deeply. And from the moment that we decided to go, the planning with our engineering team, our networking team, our infrastructure computing team, the software team, all of the preparation In advance, then all of the infrastructure, all of the logistics and the amount of technology and equipment that came in on that day, NVIDIA's infrastructure and computing infrastructure And all that technology, to training, 19 days. You don't want 19 days. Did anybody sleep 24-7? No question that nobody slept. But first of all, 19 days is incredible. But it's also kind of nice to just take a step back and just, do you know how many days days is? It's just a couple of weeks. And the mountain of technology, if you were to see it, is unbelievable. All of the wiring and the networking and, you know, networking NVIDIA gear is very different than networking hyperscale data centers. Okay. The number of wires that goes in one node, the back of a computer is all wires. And just getting this mountain of technology integrated and all the software, incredible. Yeah. So I think what Elon and the X team did, and I'm really appreciative that he acknowledges the engineering work that we did with him and the planning work and all that stuff. But what they achieved is singular, never been done before. Just to put in perspective, 100,000 GPUs, that's easily the fastest supercomputer on the planet. That's one cluster. A supercomputer that you would build would take normally three years to plan. And then they deliver the equipment and it takes one year to get it all working. We're talking about 19 days. Wow.
  Speaker 3
  What's the credit of the NVIDIA platform, right? That it's the whole processes are hardened. That's right.
  Speaker 1
  Yeah. Everything's already working. And of course, there's a whole bunch of X algorithms and X framework and X stack and things like that. And we got a ton of integration we have to do. But the planning of it was extraordinary. Just pre-planning of it. ([Time 0:44:14](https://share.snipd.com/snip/4e35d273-8e99-4492-ac9b-8c6ae3426d3e))
    - **Note:** Rearchitecting the entire hardware stack
- Harnessing AI for Organizational Growth
  Summary:
  Harnessing AI for Organizational Growth
  Transcript:
  Speaker 1
  Yeah, we hope. That's right. That's right. Right. I mean, it's good to go to school. Yes. But the goal is so that you can be productive in society later. And so it's good that we train these models. But the goal is to inference them.
  Speaker 2
  Are you already using chain of reasoning and tools like O1 in your own business to improve your own business?
  Speaker 1
  Yeah. Our cybersecurity system today can't run without our own agents. We have agents helping design chips. Hopper wouldn't be possible. Blackwell wouldn't be possible. Ruben, don't even think about it. We have digital, we have AI chip designers, AI software engineers, AI verification engineers. And we build them all inside because we have the ability and we rather use the opportunity to explore the technology ourselves.
  Speaker 2
  When I walked into the building today, somebody came up to me and said, ask Jensen about the culture. It's all about the culture. I look at the business. You know, we talk a lot about fitness and efficiency, flat organizations that can execute quickly, smaller teams. 4 million of revenue per employee, about 2 million of profits or free cash flow per employee. You've built a culture of efficiency that really has unleashed creativity and innovation and ownership and responsibility. You've broken the mold on kind of functional management. Everybody likes to talk about all of your direct reports. Is the leveraging of AI the thing that's going to continue to allow you to be hyper-creative while at the same time being efficient?
  Speaker 1
  No question. I'm hoping that someday, NVIDIA has 32,000 employees today. Right. And we have 4,000 families in Israel. I hope they're well, thinking of you guys. And I'm hoping that NVIDIA someday will be a 50,000 employee company with 100 million AI assistants. Wow. And they're in every single group. Right. We'll have a whole directory of AIs that are just generally good at doing things. We'll also have our inbox is going to full of directories of AIs that we work with that we know are really, really good specialized at our skill. And so AIs will recruit other AIs to solve problems. Right. AIs will be in Slack channels with each other. And with humans. Right, and with humans. And so we'll just be one large employee base, if you will. Some of them are digital and AI. Some of them are biological. And I'm hoping some of them even megatronics.
  Speaker 2
  I think from a business perspective, it's something that's greatly misunderstood. You You just described a company that's producing the output of a company with 150,000 people, but you're doing it with 50,000 people. Now, you didn't say I was going to get rid of all my employees. You're still growing the number of employees in the organization, but the output of that organization is going to be dramatically more. This is often misunderstood.
  Speaker 1
  AI is not – AI will change every job. AI will have a seismic impact on how people think about work. Let's acknowledge that. AI has the potential to do incredible good. It has the potential to do harm. We have to build safe AI. Yes. Let's just make that foundational. Yes. Okay. The part that is overlooked is when companies become more productive using artificial intelligence, it is likely that it manifests itself into either better earnings or better growth Or both. Right. And when that happens, the next email from the CEO is likely not a layoff announcement. Of course. Because you're growing. Yeah. And the reason for that is because we have more ideas than we can explore, and we need people to help us think through it before we automate it. Mm-hmm. That's great. And so the automation part of it, AI can help us do. Obviously, it's going to help us think through it as well. But it's still going to require us to go figure out what problems do I want to solve? There are a trillion things we can go solve. What problems does a company have to go solve? And select those ideas and figure out a way to automate and scale. And so as a result, we're going to hire more people as we become more productive. People forget that. And if you go back in time, obviously we have more ideas today than 200 years ago. That's the reason why GDPs are larger and more people are employed. And even though we're automating like crazy underneath.
  Speaker 2
  It's such an important point of this period that we're entering. One, almost all human productivity, almost all human prosperity is the byproduct of the automation and the technology of the last 200 years. I mean, you can look at, you know, from Adam Smith and Schumpeter's creative, you know, destruction. You can look at chart of GDP growth per person over the course of the last 200 years. And it's just accelerated. Yeah, right. Which leads me to this question. If you look at the 90s, our productivity growth in the United States was about 2.5% to 3% a year. Okay. And then in the 2000s, it slowed down to about 1.8%. And then the last 10 years has been the slowest productivity growth. So that's the amount of labor and capital, or the amount of output we have for a fixed amount of labor and capital. The slowest we've had on record, actually. And a lot of people have debated the reasoning for this, but if the world is as you just described, and we're going to leverage and manufacture intelligence, then isn't it the case that We're on the verge of a dramatic expansion in terms of human productivity?
  Speaker 1
  That's our hope. That's our hope. And of course, we live in this world, so we have direct evidence of it. We have direct evidence of it, either as isolated of a case as an individual researcher who is able to, with AI, now explore science at such an extraordinary scale that is unimaginable. That's productivity. Right. 100%. That are so incredible at such a high pace, and the chip complexities and the computer complexities we're building are going up exponentially while the company's employee base is Not. Measure of productivity. Correct. The software that we're developing better and better and better because we're using AI and supercomputers to help us, the number of employees is growing barely linearly. Okay. Okay. Okay. Another demonstration of ([Time 0:59:12](https://share.snipd.com/snip/6d38af68-e915-433c-8984-5296cd22bb2d))
    - **Note:** Where the world is going.
- Embrace the Moment: Value Collaboration
  Summary:
  The transformative potential of open-source AI models is immense, activating innovation across various industries and scientific fields.
  Engaging multiple AI systems in collaborative learning can significantly enhance their capabilities, akin to a group of smart individuals sharing ideas rather than a single AI learning in isolation. The Nemotron 350B model exemplifies this collaborative enhancement, acting as a superior critique that improves existing models like Lama.
  The journey in AI is not always enjoyable, but the commitment to the work and the responsibility it entails is crucial.
  Continuous learning and leveraging AI as a supportive tool can sustain relevance in the field.
  AI is increasingly viewed as a vital partner in research and problem solving, significantly enriching the quality of outputs. The next decade holds unprecedented opportunities for growth and contribution, making active participation in this AI revolution vital, as it represents a significant moment in career trajectories and societal development.
  Transcript:
  Speaker 1
  Our open source models. So first of all, Lama downloads, right? Obviously, Mark and the work that they've done, incredible. Off the charts. And it completely activated and engaged every single industry, every single field of science. Right, it's terrific. Was for synthetic data generation. Intuitively, the idea that one AI would somehow sit there and loop and generate data to learn itself, it sounds brittle. And how many times you can go around that infinite loop, that loop, you know, questionable. However, my mental image is kind of like you get a super smart person, put him into a padded room, close the door for about a month. What comes out is probably not a smarter person. But the idea that you could have two or three people sit around and we have different AIs, we have different distributions of knowledge, and we can go QA back and forth, all three of us Can come out smarter. And so the idea that you can have AI models exchanging, interacting, going back and forth, debating, reinforcement learning, synthetic data generation, for example, kind of intuitively Suggests it makes sense. And so our model, Nemotron 350B is the best model in the world for reward systems. And so it is the best critique. Okay. Interesting. Yeah. And so a fantastic model for enhancing everybody else's model. Irrespective of how great somebody else's model is, I'd recommend using Nemotron 340B to enhance and make it better. And we've already seen made Lama better, made all the other models better.
  Speaker 2
  Well, we're coming to the end. Thank goodness. As somebody who delivered DGX1 in 2016, it's really been an incredible journey. Your journey is unlikely and incredible at the same time. Thank you. You survived. Just surviving the early days was pretty extraordinary. You delivered the first DGX1 in 2016. We had this Cambrian moment in 2022. And so I'm going to ask you the question I often get asked, which is how long can you sustain what you're doing today? With 60 direct reports, you're everywhere, you're driving this revolution. Are you having fun? And is there something else that you would rather be doing?
  Speaker 1
  Is this a question about the last hour and a half? The answer is I had a great time. I had a great time. I couldn't imagine anything else I'd rather be doing. Let's see. I think it's, I don't think it's right to leave the impression that our job is fun all the time. My job isn't fun all the time. Nor do I expect it to be fun all the time. Was that ever an expectation that it was fun all the time? I think it's important all the time. I don't take myself too seriously. I take the work very seriously. I take our responsibility very seriously. I take our contribution and our moment in time very seriously. Is that always fun? No. Yeah. But do I always love it? Yes. Yeah. Like all things. Whether it is family, friends, children, is it always fun? No. Do we always love it? Absolutely, deeply. And so I think the, how long can I do this? The real question is, how long can I be relevant? And that only matters, that piece of information, that question can only be answered with how am I going to continue to learn? And I am a lot more optimistic today. I'm not saying this simply because of our topic today. I'm a lot more optimistic about my ability to stay relevant and continue to learn because of AI. I use it. I don't know, but I'm sure you guys do. I use it literally every day. There's not one piece of research that I don't involve AI with. There's not one question that even if I know the answer, I double check on it with AI. And surprisingly, the next two or three questions I ask it reveals something I didn't know. Pick your topic. You pick your topic. And I think that AI as a tutor, AI as an assistant, AI as a partner to brainstorm with, double check my work. You know, boy, you guys, it's completely revolutionary. And that's just, you know, I'm an information worker. My output is information. And so I think the contributions that I'll have on society is pretty extraordinary. Continue to make a contribution. I know that the work is important enough for me to want to continue to pursue it. And my quality of life is incredible.
  Speaker 2
  So I'll say, I can't imagine, you and I have been at this for a few decades. I can't imagine missing this moment. It's the most consequential moment of our careers. We're deeply grateful for the partnership. Don't miss the next 10 years. For the thought partnership. You make us smarter. Thank you. And I think you're really important as part of the leadership, right, that's going to optimistically and safely lead this forward. So thank you for being with us. ([Time 1:14:41](https://share.snipd.com/snip/f6c3e7d1-0559-4ee8-878f-bf15b1a2a319))
    - **Note:** Why he keeps doing it and using AI every day.
