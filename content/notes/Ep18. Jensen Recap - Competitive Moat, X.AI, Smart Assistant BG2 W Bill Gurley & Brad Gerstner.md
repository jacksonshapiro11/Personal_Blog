# Ep18. Jensen Recap - Competitive Moat, X.AI, Smart Assistant | BG2 W/ Bill Gurley & Brad Gerstner

![](https://wsrv.nl/?url=https%3A%2F%2Fd3t3ozftmdmh3i.cloudfront.net%2Fstaging%2Fpodcast_uploaded_nologo%2F40236188%2F40236188-1706073929930-da002b9be1355.jpg&w=100&h=100)

### Metadata

- Author: BG2Pod with Brad Gerstner and Bill Gurley
- Full Title: Ep18. Jensen Recap - Competitive Moat, X.AI, Smart Assistant | BG2 W/ Bill Gurley & Brad Gerstner
- Category: #podcasts



- URL: https://share.snipd.com/episode/9f7062cf-a400-4dc5-a1f4-792e5b16e872

### Highlights

- Understand the Ecosystem: Beyond GPUs to Accelerated Compute
  Summary:
  NVIDIA's competitive advantage lies in its comprehensive system-level advantages and the depth of its software integration, particularly with CUDA.
  While many perceive NVIDIA merely as a GPU company, its evolution towards an accelerated compute model highlights a strategic focus on both hardware and software. The CUDA library exemplifies this, featuring over 300 industry-specific acceleration algorithms tailored for various sectors, demonstrating NVIDIA's commitment to understanding and enhancing industry needs.
  This synergy with cloud service providers enables the optimization of mathematical operations, not just for large language models but also for traditional and emerging AI models.
  The proliferation of AI-driven workloads signifies a shift from deterministic processes to machine learning foundations, affecting overarching tasks like data processing.
  Future considerations revolve around the growing or diminishing role of CUDA among developers, evidencing its essential impact on the AI ecosystem while questioning the interplay of specialization and generalization in software development.
  Transcript:
  Speaker 1
  We spent about a third of the pod on NVIDIA's competitive moat, really trying to break it down, really trying to understand this idea of systems level advantages, the combinatorial Advantages that he has in the business. Because I think when I talk to people around the investment community, despite how well it's covered, Bill, right, there's still this idea that it's just a GPU and that somebody is going To build a better chip. They're going to come along and displace the business. And so when he said, again, it can sound like marketing speak, Sonny, when somebody says it's not a GPU company, it's an accelerated compute company. You know, we showed this chart where you can see kind of the NVIDIA full stack. And he talked about how he just built layer after layer after layer of the stack, you know, over the course of the last decade and a half. But when he said that, Sonny, I know you had a reaction to it, right? Even though you know, it's not just a GPU company, when he really broke it down, it seemed like, you know he did break new territory here.
  Speaker 3
  Yeah. Like what was great to hear from him and really, you know, positive for, you know, folks thinking about where NVIDIA lives in the stack right now is he kind of got into details and then The sub details below CUDA. And he really started going into what they're doing, very particularly on mathematical operations to accelerate their partners and how they work really closely with their partners, You know, all the cloud service providers to basically build these functions so that they can further accelerate workloads. The other little nuance that I picked up in there, he didn't focus purely on LLMs. He talked in that particular area about how they're doing that for a lot of traditional models and even newer models are being deployed for AI. And I think just really showed how they are partnering much closer on the software layer than the hardware layer alone.
  Speaker 1
  Right. I mean, in fact, you know, he talked about, you know, the CUDA library now has over 300 industry-specific acceleration algorithms, right, where they deeply learn the industry, right? So whether this is synthetic biology or this is image generation or this is autonomous driving, they learn the needs of that industry and then they accelerate the particular workloads. And that, for me, was also one of the key things. This idea that every workload is moving from kind of this deterministic, you know, handmade workload to something that's really driven by machine learning and really infused with AI and therefore benefits from acceleration, even something as ubiquitous as data processing. Yeah.
  Speaker 3
  And I shared this code sample with Bill as, you know, we were just preparing for this pod and, you know, I knew Bill processed it right away and ran it, which was, it really showed like every Piece of code that's out there now that's related to, or not every piece, many of the pieces have this like sort of if device equals CUDA, do X, and if it's not, do Y. And that's the level of impact they're having across the entire ecosystem of services and apps that are being built that are related to AI. Bill, I don't know what you thought when you saw that piece.
  Speaker 2
  Yeah, I mean, I think there's a question for the long-term that relates to CUDA. And I want to go back to the system point you made later, Brad, but while we're on CUDA is what percentage of developers will touch CUDA? And is that number going up or down? And I could see arguments on both sides. You could say the models are going to get more and more hyper-specialized and performance matters so much that the models that matter the most, the deployments that matter the most, They're going to get as close to the metal as possible. And then CUDA is going to matter. The other side you can make is those optimizations are going to live in PyTorch. They're going to live in other tools like that. And the marginal developers not going to need to know that. And I don't, I could make both arguments, but I think it's an interesting question going forward.
  Speaker 1
  I mean, I just asked chat GPT, how many CUDA developers are today, just to be on top of 3 million CUDA developers, right? And, you know, a lot more that touch CUDA that, you know, aren't specifically kind of developing on CUDA. So it is one of these things that has become pretty ubiquitous. And his point was, it's not just CUDA, of course, it's, you know, it's really full stack, you know, all the way from data ingestion, all the way through, you know, kind of the post-training. ([TimeÂ 0:04:32](https://share.snipd.com/snip/b6dbdc1b-6c7e-402b-8e51-c95e17d99031))
    - **Note:** Nvidia becoming a full stack. Optimizing work loads at different levels.
