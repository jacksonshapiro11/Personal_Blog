# Francois Chollet, Mike Knoop - LLMs Won’t Lead to AGI - $1,000,000 Prize to Find True Solution

![](https://wsrv.nl/?url=https%3A%2F%2Fsubstackcdn.com%2Ffeed%2Fpodcast%2F69345%2Fcf4775ebf853d3c71b76b82f77046da4.jpg&w=100&h=100)

### Metadata

- Author: Dwarkesh Podcast
- Full Title: Francois Chollet, Mike Knoop - LLMs Won’t Lead to AGI - $1,000,000 Prize to Find True Solution
- Category: #podcasts



- URL: https://share.snipd.com/episode/2bd3916c-7a72-4eaa-b7e0-d90a37e9945f

### Highlights

- Episode AI notes
  1. Deep learning models act as intuition machines by providing insights into the shape of the solution and guiding discrete program search efficiently.
  2. These models offer suggestions for the next best steps, determine the direction in the graph, and provide feedback on the progress.
  3. Leveraging deep learning can enhance the efficiency of program search significantly.
  4. Deep learning can be utilized for common sense knowledge and on-the-fly synthesis by fetching patterns, modules, and algorithms from a bank of resources.
  5. It can create a generalizable model with minimal data input. ([Time 0:00:00](https://share.snipd.com/episode-takeaways/3c7386aa-6a0d-4d6d-96df-38c362bfbb56))
- Leveraging Deep Learning for Program Search and Synthesis
  Summary:
  Deep learning models act as intuition machines by providing insights into the shape of the solution and guiding discrete program search efficiently.
  These models offer suggestions for the next best steps, determine the direction in the graph, and provide feedback on the progress. Leveraging deep learning can enhance the efficiency of program search significantly.
  Additionally, deep learning can be utilized for common sense knowledge and on-the-fly synthesis by fetching patterns, modules, and algorithms from a bank of resources to create a generalizable model with minimal data input.
  Transcript:
  Speaker 1
  Some intuition about the shape of the solution. And that's very much something you can get via a deep learning model. Deep learning models, they're very much like intuition machines, they're pattern matching machines. So you start from this shape of the solution, and then you're going to do actual explicit discrete program search. But you're not going to do it via brute force. You're not going to try things kind of like randomly. You're actually going to ask another deep learning model for suggestions. Like here's best likely next step. Here's where in the graph you should be going. And you can also use yet another deep learning model for feedback about, well, here's what I have so far. Is it looking good? Should I just backtrack and try something new? So I think discrete program search is going to be the key. But you want to make it dramatically better. All those of more efficient by leveraging deep learning. And by the way, another thing that you can use deep learning for is of course things like common sense knowledge and knowledge in general. On the fly synthesis engine that can adapt to new situations. But the way it adapts is that it's going to fetch from a bank of patterns, modules that could be themselves curves, that could be differentiable modules, and some others that could be Algorithmic in nature. It's going to assemble them. If you had this process that's intuition -guided, and it's going to give you, for every new situation you might be faced with, it's going to give you with a generalizable model that was Synthesized using very, very little data. Something like this would sort of arc. ([Time 0:52:28](https://share.snipd.com/snip/aabe2c71-9778-451d-a5c1-5913590aeca4))
    - **Tags:** #llms, #intellegence, #synthesis-vs-process, #system-1-vs-system-2, #memory-vs-intuition, #agi, #ai, #nature-of-thought, #scaling-laws, #favorite, #learning-(global-vs-local), #open-source-software, #reason, #disagreements, #knowledge-(intuative-vs-logical), #learning-vs-memorizing
    - **Note:** This guy thinks LLMs won’t lead to AGI that they need something else to complete them, but they’re very good at memory system one but they’re not actually good at synthesis, both are required and and this guy is proposing some system 1 learning system to identify the problem structure and bring system 2 model to actually explore the problem space emergently. we can’t just scale our way in intelligence we need some system to model, which is computationally intensive but when paired with the system one model to understand problems becomes tractable. They can remember stuff and do memory but no intuition. The thing needs to learn by itself which everyone agrees on but bulls on LLMs think that system 2 is the easy part while this guy thinks it’s the hard part. That’s the disagreement. This needs to just follow reason but how hard that is is very unclear. Intelligence is what you use when you don’t know what to do. OpenAI led to close sourced research were optimizing down the wrong route with LLMs this guy thinks we need a new direction but nothing gets published and bad results never get published which hurts innovation. Core knowledge
      System 1 vs 2 ai people differ about what the hard part of intelligence is and open source under threat.
