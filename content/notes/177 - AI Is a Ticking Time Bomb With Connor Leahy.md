# 177 - AI Is a Ticking Time Bomb With Connor Leahy

![](https://wsrv.nl/?url=https%3A%2F%2Fssl-static.libsyn.com%2Fp%2Fassets%2Fc%2Ff%2Fd%2F4%2Fcfd431701301218b%2Fbankless-logo_1.png&w=100&h=100)

### Metadata

- Author: Bankless
- Full Title: 177 - AI Is a Ticking Time Bomb With Connor Leahy
- Category: #podcasts



- URL: https://share.snipd.com/episode/39076354-06d4-4b3e-a5db-d39a60ce68ae

### Highlights

- The Increase in Blast Radius of Technology and the Potential Risks of AGI
  Transcript:
  Speaker 1
  And this is only continuing, you know, so we went from, you know, okay, you can kill like five guys, you can kill like 50 guys, you can kill 500. And now, you know, you press the button and drop a new guy out of an airplane and you can kill 50,000 people or even more than that. So if you like would graph, you know, over time, the increase in like blast radius of technology, of like, you know, misuse of a technology, or you would see an exponential. You would see that our technology is growing extremely fast, extremely quickly towards larger and larger blast radius. Not all technologies, you know, many technologies are very safe and they're very good. And I think we should invest in them and we should build them. But there are technologies that have larger and larger blast radiuses. And eventually this blast radius will encompass Earth. If our technology keeps improving, at some point, we will have technology that is so powerful that it can destroy all humans and even accidentally, it would of course be easier if you do it on purpose. But at some point, if we have powerful enough technology, we should expect things where even accents are a problem. And so I would make the claim that AGI is in this category. In the category of a trend in technology towards more and more powerful systems, where even an accident during the development of the system has larger and larger blast radius. And sometimes this is what we accept as a society. We accept that sometimes a clinical trial might go wrong. This is something that sometimes we accept to some degree, not to arbitrary degrees. We don't let anyone do any clinical trial without any oversight, of course not. Generally as a society, we think very highly of human welfare and life and that it shouldn't be endangered recklessly. ([Time 0:09:23](https://share.snipd.com/snip/fb5dd321-70bb-43e0-abbf-955b3e9714c5))
    - **Note:** The blast radius of a problem is in an accident how many people can it kill this has been increasing from the Stone Age to nukes. Ai is the next step. Exestential risk incorporates AIs being aligned with humans but also humans being aligned with humans and not using ai to kill everyone. We used to move fast and break things but when the think he can break is all of humanity we need to move slower.
- China is unlikely to build AGI and more likely to regulate it away
  Transcript:
  Speaker 1
  Totally disagree. Who's in the race? Just to say a word on China, I don't want to go too much into this. But like, there is a meme that exists, which I would like to dispel, of like, China is this massive rival here. They're going to overtake us. They're going to build AGI, whatever. I think this is really ludicrous for anyone who actually knows about China. What the Chinese Communist Party wants is stability and to stay in power more of anything. Do you think they want a crazy, uncontrollable technology that could topple governments? No. And China has been very clear multiple times that they're willing to take massive economic burdens to censor and stamp out their own tech industry. They've done this multiple times of all the countries that I think is like most likely to regulate AGI away. It's China. This is completely in their interest. It is not in the Chinese Communist Party's interest whatsoever for AGI to exist. It is completely counter to their incentives. And also they're very far behind technologically. But this is just like a common idea. I think a lot of people are perhaps perversely benefiting from holding up China as a boogeyman. But the truth is basically 100% of the risk comes exclusively from the United States of America. There is no, in my opinion, appreciable risk from non-Western countries whatsoever. Maybe this will change in your 20 years or 50 years or something. ([Time 0:36:53](https://share.snipd.com/snip/a2492d73-af26-414b-a80b-dd0c186ec9e2))
    - **Note:** Ai is built around race conditions that were the good guy and we need to have it first but then others think the same and build faster Which leads to lower safety and more global danger. People have a lot more control and agency than many think and humans can get more done than many believe. Humans have big agency. 
      Types of AI one is it turns us into paper clips the 2nd is misalignment and or accidents then there is understanding and alignment.
- The Emergence of Complexity and Coordination in Life
  Transcript:
  Speaker 1
  And then first very primitive, you know, probably like sponges or like jellyfish or something, probably a very simple organisms. But then stuff started to specialize. But to specialize, you have to coordinate better. You have to have better coordination mechanisms for a brain cell to live. It needs a lot of digestion cells to help it out and a lot of blood cells to help it out. And a lot of like the amount of infrastructure that needs to be in place and coordinated to support a human brain is ridiculous. There's a massive huge system. And everyone has to play their part. You know, some muscle cell can't just be like, I, you know, screw it. I'm going to be a neuron now. You know, if that happens, we call this cancer. This is a disease. This is not coordinated. It's not controlled. Myglobin has a lot of great work on this. I'm like bioelectricity and like cell identity and stuff like this. And then it goes further. And then we get to the meta level to the, you know, we go from the genes, the memes, you know, as Dawkins might say, where we go from purely genetic evolution or like multicellular evolution to mimetic evolution to culture evolution. There becomes now it's about cultures and tribes and civilizations and companies and gods and religions and these kinds of things. And these can also coordinate and mutate and war and change. So there's this recurring motif of life of these like higher order patterns of complexity and like, and coordination and stuff emerging. ([Time 1:24:06](https://share.snipd.com/snip/2d38fba3-a1ac-496c-ae91-498b5c966d72))
    - **Note:** Mets level of life and coordinating from the bottoms up and top down. We have cells in the brain and stomatch that must do their job when they don’t it causes cancer ie cell malfunction then you have organism who do their job at the meme level. Emergent systems behavior of life with incentive alignment. Becomes companies ect. Meta level of life. These patterns are all coordinating and cohering to the meta rules of life.
